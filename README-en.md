<div align="center">

# ğŸ¾ Clawleash

**OpenClow-style Autonomous AI Agent with Firecrawl-powered Web Scraping**

[![.NET](https://img.shields.io/badge/.NET-10.0-512BD4?style=flat-square&logo=dotnet)](https://dotnet.microsoft.com/)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)
[![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Linux%20%7C%20macOS-blue?style=flat-square)](https://github.com)

*Semantic Kernel Ã— Playwright Ã— Autonomous Agent Framework*

English | [**æ—¥æœ¬èª**](README.md)

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Configuration](#-configuration) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
  - [Web Crawler (Firecrawl-style)](#-web-crawler-firecrawl-style)
  - [Browser Automation](#-browser-automation)
  - [Advanced Browser Operations](#-advanced-browser-operations)
  - [AI-Powered Data Extraction](#-ai-powered-data-extraction)
  - [Autonomous Agent](#-autonomous-agent)
  - [Security Features](#-security-features)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Architecture](#-architecture)
- [API Reference](#-api-reference)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

**Clawleash** is an **OpenClow-style autonomous AI agent** that combines the power of:

- **Microsoft Semantic Kernel** - AI orchestration framework
- **Playwright** - Modern browser automation
- **Autonomous Agent Framework** - Self-directed task execution

It provides **Firecrawl/OpenCraw-style web scraping** capabilities with human-like autonomous browser operation, making it perfect for:

- ğŸ” Web scraping and data extraction
- ğŸ¤– Automated browser testing
- ğŸ“Š Competitive intelligence gathering
- ğŸ“° Content monitoring and aggregation
- ğŸ›’ E-commerce price tracking

---

## âœ¨ Features

### ğŸŒ Web Crawler (Firecrawl-style)

| Function | Description |
|----------|-------------|
| `ScrapeUrl` | Scrape a URL and get content in LLM-ready Markdown format |
| `CrawlWebsite` | Crawl entire websites with multi-page content extraction |
| `MapWebsite` | Generate sitemap (all URLs) from any website - extremely fast |
| `SearchWeb` | Search the web and optionally scrape content from results |
| `BatchScrape` | Bulk scrape multiple URLs simultaneously |
| `GetPageMarkdown` | Convert current page HTML to clean Markdown |

#### Scraping Capabilities
- âœ… LLM-ready formats (Markdown, structured data, HTML)
- âœ… Handles dynamic content (JS-rendered pages)
- âœ… Proxy support and anti-bot mechanisms
- âœ… Custom headers and cookies
- âœ… Screenshot capture
- âœ… Link extraction

### ğŸ–±ï¸ Browser Automation

#### Basic Operations
```csharp
NavigateTo(url)        // Navigate to URL
ClickElement(selector) // Click elements
TypeText(selector, text) // Type into input fields
SubmitForm(selector)   // Submit forms
ExecuteJavaScript(script) // Run JavaScript
```

#### Scroll Operations
```csharp
ScrollPage(pixels)     // Scroll by pixels
ScrollToBottom()       // Scroll to page bottom
ScrollToPosition(x, y) // Scroll to specific position
ScrollIntoView(selector) // Scroll element into view
```

#### Wait Operations
```csharp
WaitForSelector(selector) // Wait for element to appear
WaitForTimeout(ms)        // Wait for specific time
WaitForPageLoad()         // Wait for page load complete
```

#### Keyboard Operations
```csharp
PressKey(key)          // Press keys (Enter, Tab, Escape, etc.)
KeyboardType(text)     // Type text with keyboard
```

#### Navigation
```csharp
ReloadPage()           // Reload current page
GoBack()               // Go back in history
GoForward()            // Go forward in history
```

#### Mouse Operations
```csharp
HoverElement(selector) // Hover over element
DoubleClick(selector)  // Double-click element
RightClick(selector)   // Right-click (context menu)
DragAndDrop(src, dst)  // Drag and drop
```

### ğŸ”§ Advanced Browser Operations

#### Storage Operations
```csharp
GetCookies()           // Get all cookies
GetLocalStorage(key)   // Get localStorage values
SetLocalStorage(key, value) // Set localStorage
GetSessionStorage(key) // Get sessionStorage
```

#### Form Operations
```csharp
SelectOption(selector, value) // Select dropdown option
CheckElement(selector, check) // Check/uncheck checkbox
FillTextArea(selector, text)  // Fill textarea
```

#### Text Operations
```csharp
SelectText(startSelector, endSelector) // Select text range
CopySelection()        // Copy selected text (Ctrl+C)
Paste()                // Paste from clipboard (Ctrl+V)
FindAndHighlightText(text) // Find and highlight text
```

#### iframe Operations
```csharp
GetIframeContent(iframeSelector) // Get iframe HTML
ClickInIframe(iframeSel, elementSel) // Click inside iframe
```

#### Data Extraction
```csharp
ExtractTableData(selector) // Extract table as array
GetScrollPosition()    // Get current scroll position
```

### ğŸ¤– AI-Powered Data Extraction

#### Structured Data Extraction
```csharp
// Extract any data with natural language prompt
ExtractStructuredData("Extract product name, price, and availability")

// Extract with JSON schema
ExtractWithSchema(schemaJson)

// Extract specific types
ExtractProductInfo()   // E-commerce products
ExtractArticleInfo()   // News/blog articles
ExtractContactInfo()   // Contact information
```

#### Content Analysis
```csharp
SummarizePage()        // Generate page summary
AnalyzePageContent(question) // Ask questions about page
```

### ğŸ§  Autonomous Agent

#### Goal Execution
```csharp
// Plan and execute goal autonomously
ExecuteGoalAutonomously("Collect all product prices from example.com")

// Just plan without execution
PlanGoal("Scrape news articles from techcrunch.com")
```

#### Execution Control
```csharp
PauseExecution()       // Pause current execution
ResumeExecution()      // Resume paused execution
CancelExecution()      // Cancel execution
GetExecutionStatus()   // Get current status
```

#### Configuration
```csharp
UpdateSettings(
    maxSteps: 20,
    requireApprovalForDeletion: true
)
GetSettings()          // Get current settings
```

#### Self-Evaluation
```csharp
EvaluateLastExecution() // Evaluate and suggest improvements
```

### ğŸ”’ Security Features

| Feature | Description |
|---------|-------------|
| **URL Filtering** | Only whitelisted URLs are accessible |
| **Path Restrictions** | File operations limited to allowed directories |
| **Command Restrictions** | Only whitelisted PowerShell commands |
| **Sandbox Support** | Docker, AppContainer, Bubblewrap isolation |
| **Human-in-the-Loop** | Approval required for dangerous operations |

---

## ğŸ“¦ Installation

### Prerequisites
- [.NET 10.0 SDK](https://dotnet.microsoft.com/download)
- [PowerShell 7+](https://github.com/PowerShell/PowerShell) (optional, for PowerShell plugin)

### Quick Start

```bash
# Clone the repository
git clone https://github.com/yourusername/Clowleash.git
cd Clawleash/Clawleash

# Restore dependencies
dotnet restore

# Build the project
dotnet build

# Install Playwright browsers
pwsh bin/Debug/net10.0/.playwright/package/cli.js install

# Run the agent
dotnet run
```

### Docker (Optional)

```bash
# Build Docker image
docker build -t clawleash .

# Run in container
docker run -it clawleash
```

---

## âš™ï¸ Configuration

### appsettings.json

```json
{
  "AI": {
    "ApiKey": "your-api-key-here",
    "ModelId": "gpt-4o",
    "Endpoint": "https://api.openai.com/v1"
  },
  "Browser": {
    "Headless": true,
    "ScreenshotOnAction": false
  },
  "Security": {
    "AllowedUrls": [
      "https://example.com/*",
      "https://api.example.com/*"
    ],
    "AllowedPaths": [
      "C:\\Users\\YourName\\Documents",
      "/home/yourname/data"
    ],
    "AllowedCommands": [
      "Get-*",
      "Set-Location",
      "Write-Output",
      "ConvertTo-Json"
    ]
  },
  "Sandbox": {
    "Enabled": false,
    "Provider": "Docker"
  }
}
```

### Environment Variables

| Variable | Description |
|----------|-------------|
| `CLAWLEASH_API_KEY` | AI API key (overrides appsettings.json) |
| `CLAWLEASH_ENDPOINT` | AI API endpoint |
| `CLAWLEASH_MODEL` | Model ID to use |

### Autonomous Agent Settings

```json
{
  "AutonomousSettings": {
    "MaxSteps": 10,
    "MaxRetries": 3,
    "RequireApprovalForDangerousOperations": true,
    "RequireApprovalForFileDeletion": true,
    "RequireApprovalForFormSubmission": true,
    "MaxAutoScrolls": 5,
    "MaxAutoCrawlPages": 10,
    "StepDelayMs": 500,
    "ProgressReportInterval": 1
  }
}
```

---

## ğŸš€ Usage

### Interactive CLI Mode

```bash
dotnet run
```

```
================================
   Clawleash Agent v1.0
   OpenClow-style AI Agent
================================

ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¾ã™ã€‚çµ‚äº†ã™ã‚‹ã«ã¯ 'exit' ã¾ãŸã¯ 'quit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„

ğŸ‘¤ You: Navigate to https://example.com and take a screenshot

ğŸ¤– Clawleash:
I'll navigate to the website and take a screenshot for you.

âœ… Successfully navigated to https://example.com
ğŸ“¸ Screenshot saved (1920x1080, 245KB)

The page shows:
- Title: "Example Domain"
- Main heading: "Example Domain"
- Content: This domain is for use in illustrative examples...

ğŸ‘¤ You: Extract all the links from this page

ğŸ¤– Clawleash:
Found 2 links:
1. https://www.iana.org/domains/example
2. https://www.iana.org/domains/reserved

```

### Autonomous Execution Example

```
ğŸ‘¤ You: Collect product information from shop.example.com and save to products.json

ğŸ¤– Clawleash:
## Task Plan Created

**Goal**: Collect product information from shop.example.com
**Tasks**: 5

1. [10] Navigate to shop.example.com
2. [9] Get website sitemap
3. [8] Scrape product pages (estimated 15 pages)
4. [7] Extract product data
5. [6] âš ï¸ Save to products.json (requires approval)

[Progress] Step 1/5: Navigating to shop.example.com...
[Progress] Step 2/5: Getting sitemap...
[Progress] Step 3/5: Scraping product pages (5/15)...

âš ï¸ Approval Required:
Task: Save to products.json
Do you approve? (y/n): y

[Progress] Step 5/5: Saving data...

âœ… Completed: Collected 47 products and saved to products.json
```

### Programmatic Usage

```csharp
using Clawleash.Services;
using Clawleash.Plugins;
using Microsoft.SemanticKernel;

// Create kernel
var builder = Kernel.CreateBuilder();
builder.AddOpenAIChatCompletion("gpt-4o", "api-key");
var kernel = builder.Build();

// Add plugins
var browserManager = new BrowserManager(settings, urlValidator);
kernel.Plugins.AddFromObject(new WebCrawlerPlugin(browserManager));
kernel.Plugins.AddFromObject(new BrowserActionsPlugin(browserManager));

// Execute
var result = await kernel.InvokeAsync(
    "WebCrawler",
    "ScrapeUrl",
    new() { ["url"] = "https://example.com" }
);
Console.WriteLine(result);
```

---

## ğŸ—ï¸ Architecture

```
Clawleash/
â”‚
â”œâ”€â”€ ğŸ“‚ Plugins/                        # Semantic Kernel Plugins
â”‚   â”œâ”€â”€ RestrictedFileSystemPlugin.cs   # File operations (with security)
â”‚   â”œâ”€â”€ RestrictedPowerShellPlugin.cs   # PowerShell commands (with security)
â”‚   â”œâ”€â”€ RestrictedBrowserPlugin.cs      # Basic browser operations
â”‚   â”œâ”€â”€ WebCrawlerPlugin.cs             # Firecrawl-style web scraping
â”‚   â”œâ”€â”€ BrowserActionsPlugin.cs         # Advanced browser actions
â”‚   â”œâ”€â”€ AdvancedBrowserPlugin.cs        # Cookie, storage, forms, etc.
â”‚   â”œâ”€â”€ StructuredDataExtractionPlugin.cs # AI-powered data extraction
â”‚   â””â”€â”€ AutonomousAgentPlugin.cs        # Self-directed execution
â”‚
â”œâ”€â”€ ğŸ“‚ Services/                        # Core Services
â”‚   â”œâ”€â”€ BrowserManager.cs               # Playwright browser management
â”‚   â”œâ”€â”€ MemoryManager.cs                # Short & long-term memory
â”‚   â”œâ”€â”€ AutonomousAgentService.cs       # Autonomous execution engine
â”‚   â”œâ”€â”€ PowerShellExecutor.cs           # PowerShell command execution
â”‚   â””â”€â”€ ChatInterfaceManager.cs         # Multi-interface support
â”‚
â”œâ”€â”€ ğŸ“‚ Models/                          # Data Models
â”‚   â”œâ”€â”€ BrowserState.cs                 # Current browser state
â”‚   â”œâ”€â”€ CrawlResult.cs                  # Crawl/scrape results
â”‚   â”œâ”€â”€ AutonomousModels.cs             # Agent task & goal models
â”‚   â””â”€â”€ CommandResult.cs                # Command execution results
â”‚
â”œâ”€â”€ ğŸ“‚ Security/                        # Security Layer
â”‚   â”œâ”€â”€ UrlValidator.cs                 # URL whitelist/blacklist
â”‚   â”œâ”€â”€ PathValidator.cs                # Path access control
â”‚   â””â”€â”€ CommandValidator.cs             # Command restrictions
â”‚
â”œâ”€â”€ ğŸ“‚ Sandbox/                         # Isolation Providers
â”‚   â”œâ”€â”€ ISandboxProvider.cs             # Interface
â”‚   â”œâ”€â”€ DockerSandboxProvider.cs        # Docker isolation
â”‚   â”œâ”€â”€ AppContainerProvider.cs         # Windows AppContainer
â”‚   â””â”€â”€ BubblewrapProvider.cs           # Linux Bubblewrap
â”‚
â””â”€â”€ ğŸ“‚ Configuration/                   # Configuration
    â””â”€â”€ ClawleashSettings.cs            # Settings model
```

### Plugin System

Clawleash uses **Microsoft Semantic Kernel** plugin system:

```csharp
[KernelFunction, Description("Function description")]
public async Task<string> FunctionName(
    [Description("Parameter description")] string param)
{
    // Implementation
}
```

All functions are automatically available to the AI agent with full type safety and documentation.

---

## ğŸ“– API Reference

### WebCrawler Plugin

| Method | Parameters | Returns |
|--------|------------|---------|
| `ScrapeUrl` | url, includeScreenshot | Markdown content, links, metadata |
| `CrawlWebsite` | startUrl, maxPages, maxDepth | List of scraped pages |
| `MapWebsite` | url, searchQuery | List of URLs |
| `SearchWeb` | query, limit, scrapeContent | Search results with content |
| `BatchScrape` | urlsJson | List of scrape results |

### BrowserActions Plugin

| Method | Parameters | Description |
|--------|------------|-------------|
| `ScrollPage` | pixels | Scroll by amount |
| `WaitForElement` | selector, timeoutMs | Wait for element |
| `PressKey` | key | Press keyboard key |
| `ExecuteActions` | actionsJson | Execute multiple actions |

### AdvancedBrowser Plugin

| Method | Parameters | Description |
|--------|------------|-------------|
| `GetCookies` | - | Get all cookies |
| `GetLocalStorage` | key | Get storage value |
| `SelectOption` | selector, value | Select dropdown |
| `DragAndDrop` | source, target | Drag and drop |
| `ExtractTableData` | selector | Extract table |

### DataExtraction Plugin

| Method | Parameters | Description |
|--------|------------|-------------|
| `ExtractStructuredData` | prompt | AI-powered extraction |
| `ExtractWithSchema` | schemaJson | Schema-based extraction |
| `ExtractProductInfo` | - | Extract e-commerce data |
| `SummarizePage` | maxLength | Generate summary |

### AutonomousAgent Plugin

| Method | Parameters | Description |
|--------|------------|-------------|
| `ExecuteGoalAutonomously` | goalDescription, maxSteps | Execute goal |
| `PlanGoal` | goalDescription | Create plan only |
| `PauseExecution` | - | Pause execution |
| `UpdateSettings` | various | Update settings |

---

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/Clowleash.git

# Install development dependencies
dotnet restore

# Run tests
dotnet test

# Build release
dotnet build -c Release
```

### Code Style
- Follow [C# coding conventions](https://docs.microsoft.com/en-us/dotnet/csharp/fundamentals/coding-style/coding-conventions)
- Use meaningful variable names
- Add XML documentation for public APIs
- Write unit tests for new features

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 Clawleash

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

---

## ğŸ™ Acknowledgments

- [Microsoft Semantic Kernel](https://github.com/microsoft/semantic-kernel) - AI orchestration
- [Playwright](https://playwright.dev/) - Browser automation
- [Firecrawl](https://github.com/mendableai/firecrawl) - Inspiration for web scraping features

---

<div align="center">

**Made with â¤ï¸ by actbit**

English | [æ—¥æœ¬èª](README.md) | [â¬† Back to Top](#-clawleash)

</div>
